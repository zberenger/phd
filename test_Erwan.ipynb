{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from time import time\n",
    "from src.generate_covariance_matrix import generate_covariance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioSAR2 data keys: dict_keys(['__header__', '__version__', '__globals__', 'k', 'kz'])\n",
      "(0.26641159195579683-0.03915945768835369j)\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('./Biosar2_L_band_demo_data.mat', squeeze_me=True)#, simplify_cells=True) ## for newer scipy versions\n",
    "print(f\"BioSAR2 data keys: {mat.keys()}\")\n",
    "\n",
    "kz = mat['kz']\n",
    "k = mat['k']\n",
    "I = k[:,:,:,0]\n",
    "z = np.linspace(-10, 30, 512) # heights\n",
    "\n",
    "\n",
    "a_sub = np.arange(kz.shape[0])\n",
    "r_sub = np.arange(kz.shape[1])\n",
    "\n",
    "A_mean = []\n",
    "for i in range(10000):\n",
    "    r = np.random.randint(kz.shape[0])\n",
    "    a = np.random.randint(kz.shape[1])\n",
    "    Atmp = np.exp(-1j*kz[r, a, :].reshape(-1, 1).dot(z.reshape(1, -1)))\n",
    "\n",
    "    A_mean.append(np.mean(Atmp))\n",
    "\n",
    "print(np.mean(np.asarray(A_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.8087056255346\n",
      "150.80870787780992\n"
     ]
    }
   ],
   "source": [
    "Wrg, Waz = 8, 17 # 60 looks\n",
    "rg_ax = np.linspace(0, I.shape[0], I.shape[0], endpoint=False)\n",
    "az_ax = np.linspace(0, I.shape[1], I.shape[1], endpoint=False)\n",
    "Cov, Corr = generate_covariance_matrix(I, az_ax, rg_ax, Waz, Wrg)\n",
    "\n",
    "# SNR\n",
    "epsilon1 = 1e-1\n",
    "epsilon2 = 1e-2\n",
    "\n",
    "SNR1_6 = 20 * np.log10(np.abs((np.mean(np.trace(Cov, axis1=2, axis2=3))) - 6*epsilon1)/(6*epsilon1))\n",
    "SNR2_6 = 20 * np.log10(np.abs((np.mean(np.trace(Cov, axis1=2, axis2=3))) - 6*epsilon2)/(6*epsilon2))\n",
    "\n",
    "print(SNR1_6)\n",
    "print(SNR2_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.837080767170972\n",
      "130.82336571830385\n",
      "150.823367966781\n"
     ]
    }
   ],
   "source": [
    "### Min covariance matrix size and SNR\n",
    "Wrg = 5\n",
    "Waz = 5\n",
    "Nlook = Wrg*1.4985/2.1728 * Waz*0.4750/1.045\n",
    "print(Nlook)\n",
    "\n",
    "Cov, Corr = generate_covariance_matrix(I, az_ax, rg_ax, Waz, Wrg)\n",
    "\n",
    "# SNR\n",
    "epsilon1 = 1e-1\n",
    "epsilon2 = 1e-2\n",
    "\n",
    "SNR1_6 = 20 * np.log10(np.abs((np.mean(np.trace(Cov, axis1=2, axis2=3))) - 6*epsilon1)/(6*epsilon1))\n",
    "SNR2_6 = 20 * np.log10(np.abs((np.mean(np.trace(Cov, axis1=2, axis2=3))) - 6*epsilon2)/(6*epsilon2))\n",
    "\n",
    "print(SNR1_6)\n",
    "print(SNR2_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def zoe(x2_tmp, A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D):\n",
    "    x2 = torch.stack([x2_tmp[k]/torch.sum(x2_tmp[k]+1e-5) for k in range(len(output))])\n",
    "    res_1 = torch.stack([A_tensor[k] @ torch.diag(torch.sqrt(x2[k]+1e-5)) for k in range(len(output))])\n",
    "    zsim_tmp  = torch.stack([res_1[k] @ (A[k] + 1j*B[k])/np.sqrt(2) + np.sqrt(epsilon)*(C[k] + 1j*D[k])/np.sqrt(2)  for k in range(len(output))])\n",
    "    bf_tmp = torch.stack([torch.abs(torch.transpose(torch.conj(A_tensor[k]), 0, 1) @ zsim_tmp[k])**2 / (torch.sum(torch.abs(torch.transpose(torch.conj(A_tensor[k]), 0, 1) @ zsim_tmp[k])**2, axis=0)+1e-5) for k in range(len(output))])\n",
    "    return x2, zsim_tmp, bf_tmp, res_1\n",
    "\n",
    "def zoe_refactored(x2_tmp, A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D):\n",
    "    x2 = x2_tmp/(torch.sum(x2_tmp + 1e-5, axis=1))[..., None]\n",
    "    res_1 = torch.matmul(A_tensor.to(torch.complex128), torch.diag_embed(torch.sqrt(x2.to(torch.complex128) + 1e-5)))\n",
    "    zsim_tmp = torch.matmul(res_1, (A.to(torch.complex128) + 1j*B.to(torch.complex128)).to(torch.complex128)/np.sqrt(2)) + np.sqrt(epsilon)*(C.to(torch.complex128)+ 1j*D.to(torch.complex128)).to(torch.complex128)/np.sqrt(2)\n",
    "    res = torch.matmul(torch.transpose(torch.conj(A_tensor.to(torch.complex128)), 1, 2), zsim_tmp)\n",
    "    bf_tmp = torch.abs(res)**2 / (torch.sum(torch.abs(res)**2, dim=1, keepdims=True) + 1e-5)\n",
    "    return x2, zsim_tmp, bf_tmp, res_1\n",
    "\n",
    "def zoe_refactored_fast(x2_tmp, A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D):\n",
    "    x2 = x2_tmp/(torch.sum(x2_tmp + 1e-5, axis=1))[..., None]\n",
    "    res_1 = torch.matmul(A_tensor, torch.diag_embed(torch.sqrt(x2+1e-5)))\n",
    "    zsim_tmp = torch.matmul(res_1, (A + 1j*B)/np.sqrt(2)) + np.sqrt(epsilon)*(C+ 1j*D)/np.sqrt(2)\n",
    "    res = torch.matmul(torch.transpose(torch.conj(A_tensor), 1, 2), zsim_tmp)\n",
    "    bf_tmp = torch.abs(res)**2 / (torch.sum(torch.abs(res)**2, dim=1, keepdims=True) + 1e-5)\n",
    "    return x2, zsim_tmp, bf_tmp, res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz = 512\n",
    "Wrg = 8\n",
    "Waz = 17 \n",
    "Nim = 6\n",
    "N_batch = 32\n",
    "output = torch.zeros(N_batch, Nz, dtype= torch.float, device=device)\n",
    "x2_tmp = torch.randn(N_batch, Nz, dtype=torch.float, device=device)\n",
    "A_tensor = 100*torch.randn((N_batch, Nim, Nz), dtype=torch.cfloat, device=device) # OG 0.1\n",
    "epsilon = 1e-1\n",
    "A = torch.randn((output.shape[0], Nz, Wrg*Waz), dtype=torch.float, device=device)\n",
    "B = torch.randn((output.shape[0], Nz, Wrg*Waz), dtype=torch.float, device=device)\n",
    "C = torch.randn((output.shape[0], Nim, Wrg*Waz), dtype=torch.float, device=device)\n",
    "D = torch.randn((output.shape[0], Nim, Wrg*Waz), dtype=torch.float, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, zsim_tmp, bf_tmp, res_1 = zoe(x2_tmp.cfloat(), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_r, zsim_tmp_r, bf_tmp_r, res_1_r = zoe_refactored(x2_tmp.cfloat(), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_r2, zsim_tmp_r2, bf_tmp_r2, res_1_r2 = zoe_refactored_fast(x2_tmp.cfloat(), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2316e-08, device='cuda:0')\n",
      "tensor(4.2316e-08, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((x2 - x2_r).abs().mean())\n",
    "print((x2 - x2_r2).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0004, device='cuda:0')\n",
      "tensor(-2.9993+2.2845j, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((zsim_tmp - zsim_tmp_r).abs().mean())\n",
    "print((zsim_tmp - zsim_tmp_r2).abs().mean())\n",
    "print(torch.mean(zsim_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.9203e-10, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3821e-09, device='cuda:0')\n",
      "tensor(9.8174e-10, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0020, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((bf_tmp - bf_tmp_r).abs().mean())\n",
    "print((bf_tmp - bf_tmp_r2).abs().mean())\n",
    "print((bf_tmp_r - bf_tmp_r2).abs().mean())\n",
    "print(torch.mean(bf_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6538-0.3008j, -1.8695+0.1027j, -0.0855-0.4099j,  ...,\n",
       "          0.2334-0.2507j,  0.6743-0.8742j, -0.8482-0.0766j],\n",
       "        [-0.7299-0.6289j, -0.1354+0.5830j,  0.1341+0.6461j,  ...,\n",
       "         -0.7087-0.0432j, -0.7209+1.0367j, -0.0398+0.0323j],\n",
       "        [ 1.0574-1.1119j,  0.2343-0.0701j,  0.7678-0.3726j,  ...,\n",
       "          0.3507+1.4152j, -0.5829-0.4662j,  1.6390+0.3409j],\n",
       "        ...,\n",
       "        [-0.1033-0.1743j,  0.2996+0.0769j, -0.5779+1.3194j,  ...,\n",
       "         -0.2699+1.8064j, -0.2863+0.2019j, -0.2398+0.4330j],\n",
       "        [ 0.2329-0.3298j,  1.0692+0.3090j,  0.1478-1.0807j,  ...,\n",
       "         -0.8666+0.8352j,  0.0368+1.5160j,  0.3552+0.0325j],\n",
       "        [ 0.1852+0.9100j,  1.4460+0.8229j,  0.6847+0.9621j,  ...,\n",
       "         -0.0701-0.5126j, -0.4681-0.3853j, -1.3931+0.5570j]], device='cuda:0')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "epsilon = 1e-1\n",
    "x22 = (x2_tmp + torch.min(x2_tmp)).cfloat()\n",
    "x22 = x22/(torch.sum(x22 + 1e-5, axis=1))[..., None]\n",
    "x3_tmp = torch.randn(x2.shape, dtype=torch.float, device=device)\n",
    "x3_tmp += torch.min(x3_tmp)\n",
    "x3 = x3_tmp/(torch.sum(x3_tmp + 1e-5, axis=1))[..., None]\n",
    "out = torch.randn(N_batch, Nz, dtype=torch.float, device=device)\n",
    "A_tensor = 100*torch.randn((N_batch, Nim, Nz), dtype=torch.cfloat, device=device) # OG 0.1\n",
    "R_tensor = 10*torch.randn(N_batch, Nim, Nim, dtype=torch.cfloat, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_0(out, R_tensor, alpha, epsilon, x2, x3):\n",
    "    cov_loss = [A_tensor[k] @ torch.diag(out[k]).cfloat() @ torch.transpose(torch.conj(A_tensor[k]), 0, 1) + epsilon * torch.eye(Nim, dtype=torch.cfloat, device=device)\n",
    "                                        for k in range(len(out))]\n",
    "    corr_loss = [torch.diag(1./torch.sqrt(torch.diag(cov_loss[k])+1e-5)) @ cov_loss[k] @ torch.diag(1./torch.sqrt(torch.diag(cov_loss[k])+1e-5))\n",
    "                                        for k in range(len(out))]\n",
    "    loss1 = (torch.sum(torch.stack([torch.square(torch.linalg.norm(corr_loss[k] - R_tensor[k], ord='fro'))\n",
    "                                        for k in range(len(out))])))\n",
    "    loss2 = alpha * torch.sum(torch.square(torch.linalg.norm(10*torch.log10(x3+1e-2) - 10*torch.log10(x2+1e-2), ord=2, dim=1)))\n",
    "    loss = loss1 + loss2\n",
    "    return cov_loss, corr_loss, loss1, loss2, loss\n",
    "\n",
    "def loss_1(out, R_tensor, alpha, epsilon, x2, x3):\n",
    "    cov_loss = torch.matmul(torch.matmul(A_tensor, torch.diag_embed(out).cfloat()),\n",
    "                            torch.transpose(torch.conj(A_tensor), 1, 2)) + epsilon * torch.eye(Nim, dtype=torch.cfloat, device=device).reshape((1, Nim, Nim)).repeat(out.shape[0], 1, 1)\n",
    "    corr_loss = torch.matmul(torch.matmul(torch.diag_embed(1./torch.sqrt(torch.diagonal(cov_loss, dim1=-2, dim2=-1)+1e-5)), cov_loss),\n",
    "                             torch.diag_embed(1./torch.sqrt(torch.diagonal(cov_loss, dim1=-2, dim2=-1)+1e-5)))\n",
    "    loss1 = (torch.sum(torch.square(torch.linalg.norm(corr_loss - R_tensor, ord='fro', dim=(-1, -2)))))\n",
    "    loss2 = alpha * torch.sum(torch.square(torch.linalg.norm(10*torch.log10(x3+1e-2) - 10*torch.log10(x2+1e-2), ord=2, dim=1)))\n",
    "    loss = loss1 + loss2\n",
    "    return cov_loss, corr_loss, loss1, loss2, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_loss, corr_loss, loss1, loss2, loss = loss_0(out, R_tensor, alpha, epsilon, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_loss_1, corr_loss_1, loss1_1, loss2_1, loss_1 = loss_1(out, R_tensor, alpha, epsilon, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(4527.3789-0.0002j, device='cuda:0')\n",
      " \n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1877+0.0223j, device='cuda:0')\n",
      " \n",
      "tensor(0., device='cuda:0')\n",
      "tensor(124155.6484, device='cuda:0')\n",
      " \n",
      "tensor(0., device='cuda:0')\n",
      "tensor(17195.0117, device='cuda:0')\n",
      " \n",
      "tensor(0., device='cuda:0')\n",
      "tensor(141350.6562, device='cuda:0')\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print((torch.stack(cov_loss) - cov_loss_1).abs().mean())\n",
    "print(torch.mean(torch.stack(cov_loss)))\n",
    "print(' ')\n",
    "print((torch.stack(corr_loss) - corr_loss_1).abs().mean())\n",
    "print(torch.mean(torch.stack(corr_loss)))\n",
    "print(' ')\n",
    "print((loss1 - loss1_1).abs().mean())\n",
    "print(torch.mean(loss1))\n",
    "print(' ')\n",
    "print((loss2 - loss2_1).abs().mean())\n",
    "print(torch.mean(loss2))\n",
    "print(' ')\n",
    "print((loss - loss_1).abs().mean())\n",
    "print(torch.mean(loss))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TIME\n",
    "def time_zoe(nb_loops):\n",
    "    start = time()\n",
    "    for i in range(nb_loops):\n",
    "        x2, zsim_tmp, bf_tmp, res_1 = zoe(torch.randn(N_batch, Nz, dtype=torch.cfloat, device=device), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)\n",
    "    return time()-start\n",
    "\n",
    "def time_erwan(nb_loops):\n",
    "    start = time()\n",
    "    for i in range(nb_loops):\n",
    "        x2_r, zsim_tmp_r, bf_tmp_r, res_1_r = zoe_refactored(torch.randn(N_batch, Nz, dtype=torch.cfloat, device=device), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)\n",
    "    return time()-start\n",
    "\n",
    "def time_fast(nb_loops):\n",
    "    start = time()\n",
    "    for i in range(nb_loops):\n",
    "        x2_r2, zsim_tmp_r2, bf_tmp_r2, res_1_r2 = zoe_refactored_fast(torch.randn(N_batch, Nz, dtype=torch.cfloat, device=device), A_tensor, Nz, Wrg, Waz, Nim, epsilon, output, A, B, C, D)\n",
    "    return time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "7.499229192733765\n",
      "75.57472562789917\n",
      "7.625016450881958\n",
      "68.8656759262085\n"
     ]
    }
   ],
   "source": [
    "## TIME ON CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "print(time_zoe(10))\n",
    "print(time_zoe(100))\n",
    "\n",
    "print(time_erwan(10))\n",
    "print(time_erwan(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "zoe\n",
      "0.14377284049987793\n",
      "1.440049409866333\n",
      "14.345239162445068\n",
      "erwan\n",
      "0.006139278411865234\n",
      "0.08326864242553711\n",
      "1.1011605262756348\n",
      "fast\n",
      "0.008405447006225586\n",
      "0.06409811973571777\n",
      "0.5541741847991943\n"
     ]
    }
   ],
   "source": [
    "## TIME ON GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "print('zoe')\n",
    "print(time_zoe(10))\n",
    "print(time_zoe(100))\n",
    "print(time_zoe(1000))\n",
    "\n",
    "print('erwan')\n",
    "print(time_erwan(10))\n",
    "print(time_erwan(100))\n",
    "print(time_erwan(1000))\n",
    "\n",
    "print('fast')\n",
    "print(time_fast(10))\n",
    "print(time_fast(100))\n",
    "print(time_fast(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(32*6*10).reshape((32, 6, 10)).float().to(torch.complex128)\n",
    "b = torch.arange(32*10*65536).reshape((32, 10, 65536)).float().to(torch.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8678e+07+0.j, 1.8678e+07+0.j, 1.8678e+07+0.j,  ..., 2.1627e+07+0.j,\n",
       "         2.1627e+07+0.j, 2.1627e+07+0.j],\n",
       "        [4.8169e+07+0.j, 4.8169e+07+0.j, 4.8169e+07+0.j,  ..., 5.7671e+07+0.j,\n",
       "         5.7671e+07+0.j, 5.7672e+07+0.j],\n",
       "        [7.7660e+07+0.j, 7.7660e+07+0.j, 7.7661e+07+0.j,  ..., 9.3716e+07+0.j,\n",
       "         9.3716e+07+0.j, 9.3716e+07+0.j],\n",
       "        [1.0715e+08+0.j, 1.0715e+08+0.j, 1.0715e+08+0.j,  ..., 1.2976e+08+0.j,\n",
       "         1.2976e+08+0.j, 1.2976e+08+0.j],\n",
       "        [1.3664e+08+0.j, 1.3664e+08+0.j, 1.3664e+08+0.j,  ..., 1.6580e+08+0.j,\n",
       "         1.6581e+08+0.j, 1.6581e+08+0.j],\n",
       "        [1.6613e+08+0.j, 1.6613e+08+0.j, 1.6613e+08+0.j,  ..., 2.0185e+08+0.j,\n",
       "         2.0185e+08+0.j, 2.0185e+08+0.j]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8678e+07+0.j, 1.8678e+07+0.j, 1.8678e+07+0.j,  ..., 2.1627e+07+0.j,\n",
       "         2.1627e+07+0.j, 2.1627e+07+0.j],\n",
       "        [4.8169e+07+0.j, 4.8169e+07+0.j, 4.8169e+07+0.j,  ..., 5.7671e+07+0.j,\n",
       "         5.7671e+07+0.j, 5.7672e+07+0.j],\n",
       "        [7.7660e+07+0.j, 7.7660e+07+0.j, 7.7661e+07+0.j,  ..., 9.3716e+07+0.j,\n",
       "         9.3716e+07+0.j, 9.3716e+07+0.j],\n",
       "        [1.0715e+08+0.j, 1.0715e+08+0.j, 1.0715e+08+0.j,  ..., 1.2976e+08+0.j,\n",
       "         1.2976e+08+0.j, 1.2976e+08+0.j],\n",
       "        [1.3664e+08+0.j, 1.3664e+08+0.j, 1.3664e+08+0.j,  ..., 1.6580e+08+0.j,\n",
       "         1.6581e+08+0.j, 1.6581e+08+0.j],\n",
       "        [1.6613e+08+0.j, 1.6613e+08+0.j, 1.6613e+08+0.j,  ..., 2.0185e+08+0.j,\n",
       "         2.0185e+08+0.j, 2.0185e+08+0.j]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a[0], b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(a, b) - torch.stack([a[k] @ b[k] for k in range(32)])).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36787944 0.60653066 0.36787944]\n",
      " [0.53526143 0.8824969  0.53526143]\n",
      " [0.60653066 1.         0.60653066]\n",
      " [0.53526143 0.8824969  0.53526143]\n",
      " [0.36787944 0.60653066 0.36787944]]\n",
      "[[0.36787944 0.60653066 0.36787944]\n",
      " [0.60653066 1.         0.60653066]\n",
      " [0.36787944 0.60653066 0.36787944]]\n",
      "[[0.07511361 0.1238414  0.07511361]\n",
      " [0.1238414  0.20417996 0.1238414 ]\n",
      " [0.07511361 0.1238414  0.07511361]]\n",
      "[[0.05854983 0.09653235 0.05854983]\n",
      " [0.09653235 0.15915494 0.09653235]\n",
      " [0.05854983 0.09653235 0.05854983]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01493364, 0.02462141, 0.01493364],\n",
       "       [0.06692792, 0.11034549, 0.06692792],\n",
       "       [0.11034549, 0.18192896, 0.11034549],\n",
       "       [0.06692792, 0.11034549, 0.06692792],\n",
       "       [0.01493364, 0.02462141, 0.01493364]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GAUSSIAN FILTER\n",
    "\n",
    "row=5\n",
    "column = 3\n",
    "sig=1\n",
    "x, y = np.meshgrid(np.linspace(-1, 1, column), np.linspace(-1, 1, row))\n",
    "dst = np.sqrt(x**2+y**2)\n",
    "# normal = 1./(2.0 * np.pi * sigma**2)\n",
    "gauss = np.exp(-0.5 * np.square(dst) / np.square(sig)) # * normal\n",
    "print(gauss)\n",
    "\n",
    "def gkern(l=5, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    print(kernel)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "print(gkern(3, 1))\n",
    "\n",
    "def gen_gaussian_kernel(k_size, sigma):\n",
    "    center = k_size // 2\n",
    "    x, y = np.mgrid[0 - center : k_size - center, 0 - center : k_size - center]\n",
    "    g = 1. / (2 * np.pi * np.square(sigma)) * np.exp(-(np.square(x) + np.square(y)) / (2 * np.square(sigma)))\n",
    "    return g\n",
    "\n",
    "print(gen_gaussian_kernel(3, 1))\n",
    "\n",
    "tmp = np.zeros((5, 3))\n",
    "tmp[2,1] = 1\n",
    "gaussian_filter(tmp, 1, radius=[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
